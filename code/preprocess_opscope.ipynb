{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('w': conda)",
   "display_name": "Python 3.8.5 64-bit ('w': conda)",
   "metadata": {
    "interpreter": {
     "hash": "676aedceea7fc84534537127a7fbae2014c13e8cc8da94ff465a8c09804ac359"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from bert_serving.client import BertClient\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../train/'\n",
    "features_dir = '../features/'\n",
    "opscope = pd.read_csv(data_dir + 'base_info.csv',encoding='gbk')\n",
    "stopwords = open(data_dir + 'cn_stopwords.txt', encoding='utf8').readlines()\n",
    "stopwords = set([i.split('\\n')[0] for i in stopwords])\n",
    "opscope = pd.DataFrame([opscope.id, opscope.opscope]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache Z:\\Temp\\jieba.cache\n",
      "Loading model cost 0.656 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "def replace(x):\n",
    "    for i in set(['，', '。', '：', '；', '（', '）', '、','*', '(', ')', '\\t', '\\n']):\n",
    "        x = x.replace(i, '')\n",
    "    return x\n",
    "\n",
    "vocabulary = ''\n",
    "for i in opscope.opscope:\n",
    "    vocabulary += i\n",
    "\n",
    "vocabulary = replace(vocabulary)\n",
    "vocabulary = jieba.lcut(vocabulary)\n",
    "vocabulary = set(vocabulary).difference(stopwords)\n",
    "dictionary = {v : i for i, v in zip(range(len(vocabulary)), vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cancats(x):\n",
    "    s = ''\n",
    "    for i in x:\n",
    "        s += i + ' '\n",
    "    return s.replace('  ', ' ').replace('  ', ' ')\n",
    "\n",
    "opscope.opscope = opscope.opscope.apply(replace)\n",
    "opscope.opscope = opscope.opscope.apply(lambda x:set(jieba.lcut(x)).difference(stopwords))\n",
    "opscope.opscope = opscope.opscope.apply(cancats)\n",
    "corpus = list(opscope.opscope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BertClient()\n",
    "bc.encode(['First do it', 'then do it right', 'then do it better'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = TfidfVectorizer().fit_transform(corpus)\n",
    "# pd.DataFrame([opscope.id, vectorizer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opscope.to_csv(features_dir + 'opscope.csv', index=False)"
   ]
  }
 ]
}